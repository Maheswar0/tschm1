

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 8 &#8212; Introduction to Statistical Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/labs/notebooks/Ch08-baggboost-lab';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Chapter 9" href="Ch09-svm-lab.html" />
    <link rel="prev" title="Chapter 7" href="Ch07-nonlin-lab.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.jpeg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/logo.jpeg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    An Introduction to Statistical Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Labs</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Ch02-statlearn-lab.html">Chapter 2</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch03-linreg-lab.html">Chapter 3</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch05-resample-lab.html">Chapter 5</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch06-varselect-lab.html">Chapter 6</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch07-nonlin-lab.html">Chapter 7</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">Chapter 8</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch09-svm-lab.html">Chapter 9</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch10-deeplearning-lab.html">Chapter 10</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch11-surv-lab.html">Chapter 11</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch12-unsup-lab.html">Chapter 12</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch13-multiple-lab.html">Chapter 13</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../slides/index.html">Slides</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/tschm/isl/master?urlpath=tree/book/docs/labs/notebooks/Ch08-baggboost-lab.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tschm/isl" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tschm/isl/edit/master/book/docs/labs/notebooks/Ch08-baggboost-lab.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tschm/isl/issues/new?title=Issue%20on%20page%20%2Fdocs/labs/notebooks/Ch08-baggboost-lab.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/docs/labs/notebooks/Ch08-baggboost-lab.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 8</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Chapter 8</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-tree-based-methods">Lab: Tree-Based Methods</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-classification-trees">Fitting Classification Trees</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-regression-trees">Fitting Regression Trees</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-and-random-forests">Bagging and Random Forests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">Boosting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-additive-regression-trees">Bayesian Additive Regression Trees</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-8">
<h1>Chapter 8<a class="headerlink" href="#chapter-8" title="Permalink to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="lab-tree-based-methods">
<h1>Lab: Tree-Based Methods<a class="headerlink" href="#lab-tree-based-methods" title="Permalink to this heading">#</a></h1>
<p>We import some of our usual libraries at this top
level.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">subplots</span>
<span class="kn">from</span> <span class="nn">statsmodels.datasets</span> <span class="kn">import</span> <span class="n">get_rdataset</span>
<span class="kn">import</span> <span class="nn">sklearn.model_selection</span> <span class="k">as</span> <span class="nn">skm</span>
<span class="kn">from</span> <span class="nn">ISLP</span> <span class="kn">import</span> <span class="n">load_data</span><span class="p">,</span> <span class="n">confusion_table</span>
<span class="kn">from</span> <span class="nn">ISLP.models</span> <span class="kn">import</span> <span class="n">ModelSpec</span> <span class="k">as</span> <span class="n">MS</span>
</pre></div>
</div>
</div>
</div>
<p>We also  collect the new imports
needed for this lab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="p">(</span><span class="n">DecisionTreeClassifier</span> <span class="k">as</span> <span class="n">DTC</span><span class="p">,</span>
                          <span class="n">DecisionTreeRegressor</span> <span class="k">as</span> <span class="n">DTR</span><span class="p">,</span>
                          <span class="n">plot_tree</span><span class="p">,</span>
                          <span class="n">export_text</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="p">(</span><span class="n">accuracy_score</span><span class="p">,</span>
                             <span class="n">log_loss</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> \
     <span class="p">(</span><span class="n">RandomForestRegressor</span> <span class="k">as</span> <span class="n">RF</span><span class="p">,</span>
      <span class="n">GradientBoostingRegressor</span> <span class="k">as</span> <span class="n">GBR</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">ISLP.bart</span> <span class="kn">import</span> <span class="n">BART</span>
</pre></div>
</div>
</div>
</div>
<section id="fitting-classification-trees">
<h2>Fitting Classification Trees<a class="headerlink" href="#fitting-classification-trees" title="Permalink to this heading">#</a></h2>
<p>We first use classification trees to analyze the  <code class="docutils literal notranslate"><span class="pre">Carseats</span></code>  data set.
In these data, <code class="docutils literal notranslate"><span class="pre">Sales</span></code> is a continuous variable, and so we begin
by recoding it as a binary variable. We use the <code class="docutils literal notranslate"><span class="pre">where()</span></code>
function to create a variable, called <code class="docutils literal notranslate"><span class="pre">High</span></code>, which takes on a
value of <code class="docutils literal notranslate"><span class="pre">Yes</span></code> if the <code class="docutils literal notranslate"><span class="pre">Sales</span></code> variable exceeds 8, and takes
on a value of <code class="docutils literal notranslate"><span class="pre">No</span></code> otherwise.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Carseats</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;Carseats&#39;</span><span class="p">)</span>
<span class="n">High</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">Carseats</span><span class="o">.</span><span class="n">Sales</span> <span class="o">&gt;</span> <span class="mi">8</span><span class="p">,</span>
                <span class="s2">&quot;Yes&quot;</span><span class="p">,</span>
                <span class="s2">&quot;No&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We now use <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier()</span></code>  to fit a classification tree in
order to predict <code class="docutils literal notranslate"><span class="pre">High</span></code> using all variables but <code class="docutils literal notranslate"><span class="pre">Sales</span></code>.
To do so, we must form a model matrix as we did when fitting regression
models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">MS</span><span class="p">(</span><span class="n">Carseats</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Sales&#39;</span><span class="p">),</span> <span class="n">intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Carseats</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have converted <code class="docutils literal notranslate"><span class="pre">D</span></code> from a data frame to an array <code class="docutils literal notranslate"><span class="pre">X</span></code>, which is needed in some of the analysis below. We also need the <code class="docutils literal notranslate"><span class="pre">feature_names</span></code> for annotating our plots later.</p>
<p>There are several options needed to specify the  classifier,
such as <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> (how deep to grow the tree), <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code>
(minimum number of observations in a node to be eligible for splitting)
and <code class="docutils literal notranslate"><span class="pre">criterion</span></code> (whether to use Gini or cross-entropy as the split criterion).
We also set <code class="docutils literal notranslate"><span class="pre">random_state</span></code> for reproducibility; ties in the split criterion are broken at random.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">DTC</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span>
          <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
          <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>        
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">High</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">DecisionTreeClassifier</label><div class="sk-toggleable__content"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3, random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<p>In our discussion of qualitative features in Section 3.3,
we noted that for a linear regression model such a feature could be
represented by including a matrix of dummy variables (one-hot-encoding) in the model
matrix, using the formula notation of <code class="docutils literal notranslate"><span class="pre">statsmodels</span></code>.
As mentioned in Section 8.1, there is a more
natural way to handle qualitative features when building a decision
tree, that does not require such dummy variables; each split amounts to partitioning the levels into two groups.
However,
the <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> implementation of decision trees does not take
advantage of this approach; instead it simply treats the one-hot-encoded levels as separate variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">High</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.79
</pre></div>
</div>
</div>
</div>
<p>With only the default arguments, the training error rate is
21%.
For classification trees, we can
access the value of the deviance using <code class="docutils literal notranslate"><span class="pre">log_loss()</span></code>,</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{equation*}
\begin{split}
-2 \sum_m \sum_k n_{mk} \log \hat{p}_{mk},
\end{split}
\end{equation*}\]</div>
<p>where <span class="math notranslate nohighlight">\(n_{mk}\)</span> is the number of observations in the <span class="math notranslate nohighlight">\(m\)</span>th terminal
node that belong to the <span class="math notranslate nohighlight">\(k\)</span>th class.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">resid_dev</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">log_loss</span><span class="p">(</span><span class="n">High</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
<span class="n">resid_dev</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.4710647062649358
</pre></div>
</div>
</div>
</div>
<p>This is closely related to the <em>entropy</em>, defined in (8.7).
A small deviance indicates a
tree that provides a good fit to the (training) data.</p>
<p>One of the most attractive properties of trees is that they can
be graphically displayed. Here we use the <code class="docutils literal notranslate"><span class="pre">plot()</span></code>  function
to display the tree structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
          <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/c9c7aeb327e11ee86f0f1c1f7c5c40161719f6b49e623b92710f8dddfa649633.png" src="../../../_images/c9c7aeb327e11ee86f0f1c1f7c5c40161719f6b49e623b92710f8dddfa649633.png" />
</div>
</div>
<p>The most important indicator of <code class="docutils literal notranslate"><span class="pre">Sales</span></code> appears to be <code class="docutils literal notranslate"><span class="pre">ShelveLoc</span></code>.</p>
<p>We can see a text representation of the tree using
<code class="docutils literal notranslate"><span class="pre">export_text()</span></code>, which displays the split
criterion (e.g. <code class="docutils literal notranslate"><span class="pre">Price</span> <span class="pre">&lt;=</span> <span class="pre">92.5</span></code>) for each branch.
For leaf nodes it shows the overall prediction<br />
(<code class="docutils literal notranslate"><span class="pre">Yes</span></code> or <code class="docutils literal notranslate"><span class="pre">No</span></code>).
We can also see the number of observations in that
leaf that take on values of <code class="docutils literal notranslate"><span class="pre">Yes</span></code> and <code class="docutils literal notranslate"><span class="pre">No</span></code> by specifying  <code class="docutils literal notranslate"><span class="pre">show_weights=True</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">export_text</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span>
                  <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
                  <span class="n">show_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>|--- ShelveLoc[Good] &lt;= 0.50
|   |--- Price &lt;= 92.50
|   |   |--- Income &lt;= 57.00
|   |   |   |--- weights: [7.00, 3.00] class: No
|   |   |--- Income &gt;  57.00
|   |   |   |--- weights: [7.00, 29.00] class: Yes
|   |--- Price &gt;  92.50
|   |   |--- Advertising &lt;= 13.50
|   |   |   |--- weights: [183.00, 41.00] class: No
|   |   |--- Advertising &gt;  13.50
|   |   |   |--- weights: [20.00, 25.00] class: Yes
|--- ShelveLoc[Good] &gt;  0.50
|   |--- Price &lt;= 135.00
|   |   |--- US[Yes] &lt;= 0.50
|   |   |   |--- weights: [6.00, 11.00] class: Yes
|   |   |--- US[Yes] &gt;  0.50
|   |   |   |--- weights: [2.00, 49.00] class: Yes
|   |--- Price &gt;  135.00
|   |   |--- Income &lt;= 46.00
|   |   |   |--- weights: [6.00, 0.00] class: No
|   |   |--- Income &gt;  46.00
|   |   |   |--- weights: [5.00, 6.00] class: Yes
</pre></div>
</div>
</div>
</div>
<p>In order to properly evaluate the performance of a classification tree
on these data, we must estimate the test error rather than simply
computing the training error. We split the observations into a
training set and a test set, build the tree using the training set,
and evaluate its performance on the test data. This pattern is
similar to that in Chapter 6, with the linear models
replaced here by decision trees — the code for validation
is almost identical. This approach leads to correct predictions
for 68.5% of the locations in the test data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">validation</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                              <span class="n">test_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                              <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span>
                             <span class="n">D</span><span class="p">,</span>
                             <span class="n">High</span><span class="p">,</span>
                             <span class="n">cv</span><span class="o">=</span><span class="n">validation</span><span class="p">)</span>
<span class="n">results</span><span class="p">[</span><span class="s1">&#39;test_score&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.685])
</pre></div>
</div>
</div>
</div>
<p>Next, we consider whether pruning the tree might lead to improved
classification performance. We first split the data into a training and
test set. We will use cross-validation to prune the tree on the training
set, and then evaluate the performance of the pruned tree on the test
set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
 <span class="n">X_test</span><span class="p">,</span>
 <span class="n">High_train</span><span class="p">,</span>
 <span class="n">High_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                   <span class="n">High</span><span class="p">,</span>
                                   <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
                                   <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                                   
</pre></div>
</div>
</div>
</div>
<p>We first refit the full tree on the training set; here we do not set a <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> parameter, since we will learn that through cross-validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">DTC</span><span class="p">(</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">High_train</span><span class="p">)</span>
<span class="n">accuracy_score</span><span class="p">(</span><span class="n">High_test</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.735
</pre></div>
</div>
</div>
</div>
<p>Next we use the <code class="docutils literal notranslate"><span class="pre">cost_complexity_pruning_path()</span></code> method of
<code class="docutils literal notranslate"><span class="pre">clf</span></code> to extract cost-complexity values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ccp_path</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">High_train</span><span class="p">)</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">KFold</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span>
                  <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This yields a set of impurities and <span class="math notranslate nohighlight">\(\alpha\)</span> values
from which we can extract an optimal one by cross-validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span>
                        <span class="p">{</span><span class="s1">&#39;ccp_alpha&#39;</span><span class="p">:</span> <span class="n">ccp_path</span><span class="o">.</span><span class="n">ccp_alphas</span><span class="p">},</span>
                        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
                        <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">High_train</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.685
</pre></div>
</div>
</div>
</div>
<p>Let’s take a look at the pruned true.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">best_</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">best_</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
          <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/4d0d69ad1ba2f10ce683f1055135bb44b201be2ff47cc226c736929f0af4baf6.png" src="../../../_images/4d0d69ad1ba2f10ce683f1055135bb44b201be2ff47cc226c736929f0af4baf6.png" />
</div>
</div>
<p>This is quite a bushy tree. We could count the leaves, or query
<code class="docutils literal notranslate"><span class="pre">best_</span></code> instead.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_</span><span class="o">.</span><span class="n">tree_</span><span class="o">.</span><span class="n">n_leaves</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>30
</pre></div>
</div>
</div>
</div>
<p>The tree with 30 terminal
nodes results in the lowest cross-validation error rate, with an accuracy of
68.5%. How well does this pruned tree perform on the test data set? Once
again, we apply the <code class="docutils literal notranslate"><span class="pre">predict()</span></code>  function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">High_test</span><span class="p">,</span>
                     <span class="n">best_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
<span class="n">confusion</span> <span class="o">=</span> <span class="n">confusion_table</span><span class="p">(</span><span class="n">best_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span>
                            <span class="n">High_test</span><span class="p">)</span>
<span class="n">confusion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.72
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Truth</th>
      <th>No</th>
      <th>Yes</th>
    </tr>
    <tr>
      <th>Predicted</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>No</th>
      <td>94</td>
      <td>32</td>
    </tr>
    <tr>
      <th>Yes</th>
      <td>24</td>
      <td>50</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Now 72.0% of the test observations are correctly classified, which is slightly worse than the error for the full tree (with 35 leaves). So cross-validation has not helped us much here; it only pruned off 5 leaves, at a cost of a slightly worse error. These results would change if we were to change the random number seeds above; even though cross-validation gives an unbiased approach to model selection, it does have variance.</p>
</section>
<section id="fitting-regression-trees">
<h2>Fitting Regression Trees<a class="headerlink" href="#fitting-regression-trees" title="Permalink to this heading">#</a></h2>
<p>Here we fit a regression tree to the  <code class="docutils literal notranslate"><span class="pre">Boston</span></code>  data set. The
steps are similar to those for classification trees.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Boston</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s2">&quot;Boston&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MS</span><span class="p">(</span><span class="n">Boston</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;medv&#39;</span><span class="p">),</span> <span class="n">intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">Boston</span><span class="p">)</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">D</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>First, we split the data into training and test sets, and fit the tree
to the training data. Here we use 30% of the data for the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
 <span class="n">X_test</span><span class="p">,</span>
 <span class="n">y_train</span><span class="p">,</span>
 <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                <span class="n">Boston</span><span class="p">[</span><span class="s1">&#39;medv&#39;</span><span class="p">],</span>
                                <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
                                <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Having formed  our training  and test data sets, we fit the regression tree.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reg</span> <span class="o">=</span> <span class="n">DTR</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
          <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/25f4bf15114dae8842f342297dc262bbda7fb939115d219292a3c3e95a78d48f.png" src="../../../_images/25f4bf15114dae8842f342297dc262bbda7fb939115d219292a3c3e95a78d48f.png" />
</div>
</div>
<p>The variable <code class="docutils literal notranslate"><span class="pre">lstat</span></code> measures the percentage of individuals with
lower socioeconomic status. The tree indicates that lower
values of <code class="docutils literal notranslate"><span class="pre">lstat</span></code> correspond to more expensive houses.
The tree predicts a median house price of $12,042 for small-sized homes (<code class="docutils literal notranslate"><span class="pre">rm</span> <span class="pre">&lt;</span> <span class="pre">6.8</span></code>), in
suburbs in which residents have low socioeconomic status (<code class="docutils literal notranslate"><span class="pre">lstat</span>&#160; <span class="pre">&gt;</span> <span class="pre">14.4</span></code>) and the crime-rate is moderate (<code class="docutils literal notranslate"><span class="pre">crim</span> <span class="pre">&gt;</span> <span class="pre">5.8</span></code>).</p>
<p>Now we use the cross-validation function to see whether pruning
the tree will improve performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ccp_path</span> <span class="o">=</span> <span class="n">reg</span><span class="o">.</span><span class="n">cost_complexity_pruning_path</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">KFold</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span>
                  <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                  <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">skm</span><span class="o">.</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span>
                        <span class="p">{</span><span class="s1">&#39;ccp_alpha&#39;</span><span class="p">:</span> <span class="n">ccp_path</span><span class="o">.</span><span class="n">ccp_alphas</span><span class="p">},</span>
                        <span class="n">refit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,</span>
                        <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">)</span>
<span class="n">G</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In keeping with the cross-validation results, we use the pruned tree
to make predictions on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">best_</span> <span class="o">=</span> <span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">best_</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>28.069857549754044
</pre></div>
</div>
</div>
</div>
<p>In other words, the test set MSE associated with the regression tree
is 28.07.  The square root of
the MSE is therefore around
5.30,
indicating that this model leads to test predictions that are within around
$5300
of the true median home value for the suburb.</p>
<p>Let’s plot the best tree to see how interpretable it is.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">plot_tree</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">,</span>
          <span class="n">feature_names</span><span class="o">=</span><span class="n">feature_names</span><span class="p">,</span>
          <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/ebb2d935e910eaf0ff81d4e12535b17f7bb5ed5e8cb680301996809784eaf3bb.png" src="../../../_images/ebb2d935e910eaf0ff81d4e12535b17f7bb5ed5e8cb680301996809784eaf3bb.png" />
</div>
</div>
</section>
<section id="bagging-and-random-forests">
<h2>Bagging and Random Forests<a class="headerlink" href="#bagging-and-random-forests" title="Permalink to this heading">#</a></h2>
<p>Here we apply bagging and random forests to the <code class="docutils literal notranslate"><span class="pre">Boston</span></code> data, using
the <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor()</span></code> from the <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code> package. Recall
that bagging is simply a special case of a random forest with
<span class="math notranslate nohighlight">\(m=p\)</span>. Therefore, the <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor()</span></code>  function can be used to
perform both bagging and random forests. We start with bagging.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bag_boston</span> <span class="o">=</span> <span class="n">RF</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">bag_boston</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestRegressor(max_features=12, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">RandomForestRegressor</label><div class="sk-toggleable__content"><pre>RandomForestRegressor(max_features=12, random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<p>The argument <code class="docutils literal notranslate"><span class="pre">max_features</span></code> indicates that all 12 predictors should
be considered for each split of the tree — in other words, that
bagging should be done.  How well does this bagged model perform on
the test set?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_hat_bag</span> <span class="o">=</span> <span class="n">bag_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_hat_bag</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_hat_bag</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14.634700151315787
</pre></div>
</div>
<img alt="../../../_images/02076f5629b8457f231d940dbbdd7ba9780be1bea68d340b224185c39669d4b6.png" src="../../../_images/02076f5629b8457f231d940dbbdd7ba9780be1bea68d340b224185c39669d4b6.png" />
</div>
</div>
<p>The test set MSE associated with the bagged regression tree is
14.63, about half that obtained using an optimally-pruned single
tree.  We could change the number of trees grown from the default of
100 by
using the <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> argument:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bag_boston</span> <span class="o">=</span> <span class="n">RF</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat_bag</span> <span class="o">=</span> <span class="n">bag_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_hat_bag</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14.605662565263161
</pre></div>
</div>
</div>
</div>
<p>There is not much change. Bagging and random forests cannot overfit by
increasing the number of trees, but can underfit if the number is too small.</p>
<p>Growing a random forest proceeds in exactly the same way, except that
we use a smaller value of the <code class="docutils literal notranslate"><span class="pre">max_features</span></code> argument. By default,
<code class="docutils literal notranslate"><span class="pre">RandomForestRegressor()</span></code>  uses <span class="math notranslate nohighlight">\(p\)</span> variables when building a random
forest of regression trees (i.e. it defaults to bagging), and <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier()</span></code> uses
<span class="math notranslate nohighlight">\(\sqrt{p}\)</span> variables when building a
random forest of classification trees. Here we use <code class="docutils literal notranslate"><span class="pre">max_features=6</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">RF_boston</span> <span class="o">=</span> <span class="n">RF</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
               <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat_RF</span> <span class="o">=</span> <span class="n">RF_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_hat_RF</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20.04276446710527
</pre></div>
</div>
</div>
</div>
<p>The test set MSE is 20.04;
this indicates that random forests did somewhat worse than bagging
in this case. Extracting the <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> values from the fitted model, we can view the
importance of each variable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_imp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
    <span class="p">{</span><span class="s1">&#39;importance&#39;</span><span class="p">:</span><span class="n">RF_boston</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">},</span>
    <span class="n">index</span><span class="o">=</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">feature_imp</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>importance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>lstat</th>
      <td>0.356203</td>
    </tr>
    <tr>
      <th>rm</th>
      <td>0.332163</td>
    </tr>
    <tr>
      <th>ptratio</th>
      <td>0.067270</td>
    </tr>
    <tr>
      <th>crim</th>
      <td>0.055404</td>
    </tr>
    <tr>
      <th>indus</th>
      <td>0.053851</td>
    </tr>
    <tr>
      <th>dis</th>
      <td>0.041582</td>
    </tr>
    <tr>
      <th>nox</th>
      <td>0.035225</td>
    </tr>
    <tr>
      <th>tax</th>
      <td>0.025355</td>
    </tr>
    <tr>
      <th>age</th>
      <td>0.021506</td>
    </tr>
    <tr>
      <th>rad</th>
      <td>0.004784</td>
    </tr>
    <tr>
      <th>chas</th>
      <td>0.004203</td>
    </tr>
    <tr>
      <th>zn</th>
      <td>0.002454</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>This
is a relative measure of the total decrease in node impurity that results from
splits over that variable, averaged over all trees (this was plotted in Figure 8.9 for a model fit to the <code class="docutils literal notranslate"><span class="pre">Heart</span></code> data).</p>
<p>The results indicate that across all of the trees considered in the
random forest, the wealth level of the community (<code class="docutils literal notranslate"><span class="pre">lstat</span></code>) and the
house size (<code class="docutils literal notranslate"><span class="pre">rm</span></code>) are by far the two most important variables.</p>
</section>
<section id="boosting">
<h2>Boosting<a class="headerlink" href="#boosting" title="Permalink to this heading">#</a></h2>
<p>Here we use <code class="docutils literal notranslate"><span class="pre">GradientBoostingRegressor()</span></code> from <code class="docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code>
to fit boosted regression trees to the <code class="docutils literal notranslate"><span class="pre">Boston</span></code> data
set. For classification we would  use <code class="docutils literal notranslate"><span class="pre">GradientBoostingClassifier()</span></code>.
The argument <code class="docutils literal notranslate"><span class="pre">n_estimators=5000</span></code>
indicates that we want 5000 trees, and the option
<code class="docutils literal notranslate"><span class="pre">max_depth=3</span></code> limits the depth of each tree. The
argument <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> is the <span class="math notranslate nohighlight">\(\lambda\)</span>
mentioned earlier in the description of boosting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boost_boston</span> <span class="o">=</span> <span class="n">GBR</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                   <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
                   <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                   <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">boost_boston</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>GradientBoostingRegressor(learning_rate=0.001, n_estimators=5000,
                          random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">GradientBoostingRegressor</label><div class="sk-toggleable__content"><pre>GradientBoostingRegressor(learning_rate=0.001, n_estimators=5000,
                          random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<p>We can see how the training error decreases with the <code class="docutils literal notranslate"><span class="pre">train_score_</span></code> attribute.
To get an idea of how the test error decreases we can use the
<code class="docutils literal notranslate"><span class="pre">staged_predict()</span></code> method to get the predicted values along the path.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">boost_boston</span><span class="o">.</span><span class="n">train_score_</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">y_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">boost_boston</span><span class="o">.</span><span class="n">staged_predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
   <span class="n">test_error</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plot_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">boost_boston</span><span class="o">.</span><span class="n">train_score_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plot_idx</span><span class="p">,</span>
        <span class="n">boost_boston</span><span class="o">.</span><span class="n">train_score_</span><span class="p">,</span>
        <span class="s1">&#39;b&#39;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plot_idx</span><span class="p">,</span>
        <span class="n">test_error</span><span class="p">,</span>
        <span class="s1">&#39;r&#39;</span><span class="p">,</span>
        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/766b6a5d86533d5ee88185f5774eeac00fd0d5974e49873a9f4ae7dd5f691455.png" src="../../../_images/766b6a5d86533d5ee88185f5774eeac00fd0d5974e49873a9f4ae7dd5f691455.png" />
</div>
</div>
<p>We now use the boosted model to predict <code class="docutils literal notranslate"><span class="pre">medv</span></code> on the test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat_boost</span> <span class="o">=</span> <span class="n">boost_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">);</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_hat_boost</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14.481405918831591
</pre></div>
</div>
</div>
</div>
<p>The test MSE obtained is 14.48,
similar to the test MSE for bagging. If we want to, we can
perform boosting with a different value of the shrinkage parameter
<span class="math notranslate nohighlight">\(\lambda\)</span> in  (8.10). The default value is 0.001, but
this is easily modified.  Here we take <span class="math notranslate nohighlight">\(\lambda=0.2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">boost_boston</span> <span class="o">=</span> <span class="n">GBR</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                   <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                   <span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                   <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">boost_boston</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span>
                 <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat_boost</span> <span class="o">=</span> <span class="n">boost_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">);</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_hat_boost</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>14.501514553719565
</pre></div>
</div>
</div>
</div>
<p>In this case, using <span class="math notranslate nohighlight">\(\lambda=0.2\)</span> leads to a almost the same test MSE
as <span class="math notranslate nohighlight">\(\lambda=0.001\)</span>.</p>
</section>
<section id="bayesian-additive-regression-trees">
<h2>Bayesian Additive Regression Trees<a class="headerlink" href="#bayesian-additive-regression-trees" title="Permalink to this heading">#</a></h2>
<p>In this section we demonstrate a  <code class="docutils literal notranslate"><span class="pre">Python</span></code> implementation of BART found in the
<code class="docutils literal notranslate"><span class="pre">ISLP.bart</span></code> package. We fit a  model
to the <code class="docutils literal notranslate"><span class="pre">Boston</span></code> housing data set. This <code class="docutils literal notranslate"><span class="pre">BART()</span></code> estimator is
designed for quantitative outcome variables, though other implementations are available for
fitting logistic and probit models to categorical outcomes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bart_boston</span> <span class="o">=</span> <span class="n">BART</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">burnin</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ndraw</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">bart_boston</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>BART(burnin=5, ndraw=15, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox" checked><label for="sk-estimator-id-4" class="sk-toggleable__label sk-toggleable__label-arrow">BART</label><div class="sk-toggleable__content"><pre>BART(burnin=5, ndraw=15, random_state=0)</pre></div></div></div></div></div></div></div>
</div>
<p>On this data set, with this split into test and training, we see that the test error of BART is similar to that of  random forest.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yhat_test</span> <span class="o">=</span> <span class="n">bart_boston</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">yhat_test</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>20.73918541749876
</pre></div>
</div>
</div>
</div>
<p>We can check how many times each variable appeared in the collection of trees.
This gives a summary similar to the variable importance plot for boosting and random forests.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">var_inclusion</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">bart_boston</span><span class="o">.</span><span class="n">variable_inclusion_</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span>
                               <span class="n">index</span><span class="o">=</span><span class="n">D</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">var_inclusion</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>crim       25.466667
zn         30.600000
indus      24.933333
chas       21.133333
nox        27.333333
rm         28.800000
age        23.466667
dis        26.000000
rad        25.000000
tax        21.733333
ptratio    26.800000
lstat      31.866667
dtype: float64
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/labs/notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Ch07-nonlin-lab.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 7</p>
      </div>
    </a>
    <a class="right-next"
       href="Ch09-svm-lab.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 9</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Chapter 8</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-tree-based-methods">Lab: Tree-Based Methods</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-classification-trees">Fitting Classification Trees</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-regression-trees">Fitting Regression Trees</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-and-random-forests">Bagging and Random Forests</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#boosting">Boosting</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-additive-regression-trees">Bayesian Additive Regression Trees</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Trevor Hastie et al.
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>