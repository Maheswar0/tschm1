

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Chapter 12 &#8212; Introduction to Statistical Learning</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/labs/notebooks/Ch12-unsup-lab';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Chapter 13" href="Ch13-multiple-lab.html" />
    <link rel="prev" title="Chapter 11" href="Ch11-surv-lab.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.jpeg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/logo.jpeg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    An Introduction to Statistical Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../index.html">Labs</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Ch02-statlearn-lab.html">Chapter 2</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch03-linreg-lab.html">Chapter 3</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch05-resample-lab.html">Chapter 5</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch06-varselect-lab.html">Chapter 6</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch07-nonlin-lab.html">Chapter 7</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch08-baggboost-lab.html">Chapter 8</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch09-svm-lab.html">Chapter 9</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch10-deeplearning-lab.html">Chapter 10</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch11-surv-lab.html">Chapter 11</a></li>

<li class="toctree-l2 current active"><a class="current reference internal" href="#">Chapter 12</a></li>

<li class="toctree-l2"><a class="reference internal" href="Ch13-multiple-lab.html">Chapter 13</a></li>

</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../slides/index.html">Slides</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/tschm/isl/master?urlpath=tree/book/docs/labs/notebooks/Ch12-unsup-lab.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/tschm/isl" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tschm/isl/edit/master/book/docs/labs/notebooks/Ch12-unsup-lab.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/tschm/isl/issues/new?title=Issue%20on%20page%20%2Fdocs/labs/notebooks/Ch12-unsup-lab.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/docs/labs/notebooks/Ch12-unsup-lab.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Chapter 12</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Chapter 12</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-unsupervised-learning">Lab: Unsupervised Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-components-analysis">Principal Components Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-completion">Matrix Completion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-clustering"><span class="math notranslate nohighlight">\(K\)</span>-Means Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-clustering">Hierarchical Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nci60-data-example">NCI60 Data Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-on-the-nci60-data">PCA on the NCI60 Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-the-observations-of-the-nci60-data">Clustering the Observations of the NCI60 Data</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="chapter-12">
<h1>Chapter 12<a class="headerlink" href="#chapter-12" title="Permalink to this heading">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="lab-unsupervised-learning">
<h1>Lab: Unsupervised Learning<a class="headerlink" href="#lab-unsupervised-learning" title="Permalink to this heading">#</a></h1>
<p>In this lab we demonstrate PCA and clustering on several datasets.
As in other labs, we import some of our libraries at this top
level. This makes the code more readable, as scanning the first few
lines of the notebook tell us what libraries are used in this
notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">statsmodels.datasets</span> <span class="kn">import</span> <span class="n">get_rdataset</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">ISLP</span> <span class="kn">import</span> <span class="n">load_data</span>
</pre></div>
</div>
</div>
</div>
<p>We also collect the new imports
needed for this lab.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> \
     <span class="p">(</span><span class="n">KMeans</span><span class="p">,</span>
      <span class="n">AgglomerativeClustering</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="kn">import</span> \
     <span class="p">(</span><span class="n">dendrogram</span><span class="p">,</span>
      <span class="n">cut_tree</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">ISLP.cluster</span> <span class="kn">import</span> <span class="n">compute_linkage</span>
</pre></div>
</div>
</div>
</div>
<section id="principal-components-analysis">
<h2>Principal Components Analysis<a class="headerlink" href="#principal-components-analysis" title="Permalink to this heading">#</a></h2>
<p>In this lab, we perform PCA on  <code class="docutils literal notranslate"><span class="pre">USArrests</span></code>, a data set in the
<code class="docutils literal notranslate"><span class="pre">R</span></code> computing environment.
We retrieve the data using <code class="docutils literal notranslate"><span class="pre">get_rdataset()</span></code>, which can fetch data from
many standard <code class="docutils literal notranslate"><span class="pre">R</span></code> packages.</p>
<p>The rows of the data set contain the 50 states, in alphabetical order.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">USArrests</span> <span class="o">=</span> <span class="n">get_rdataset</span><span class="p">(</span><span class="s1">&#39;USArrests&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="n">USArrests</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Murder</th>
      <th>Assault</th>
      <th>UrbanPop</th>
      <th>Rape</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alabama</th>
      <td>13.2</td>
      <td>236</td>
      <td>58</td>
      <td>21.2</td>
    </tr>
    <tr>
      <th>Alaska</th>
      <td>10.0</td>
      <td>263</td>
      <td>48</td>
      <td>44.5</td>
    </tr>
    <tr>
      <th>Arizona</th>
      <td>8.1</td>
      <td>294</td>
      <td>80</td>
      <td>31.0</td>
    </tr>
    <tr>
      <th>Arkansas</th>
      <td>8.8</td>
      <td>190</td>
      <td>50</td>
      <td>19.5</td>
    </tr>
    <tr>
      <th>California</th>
      <td>9.0</td>
      <td>276</td>
      <td>91</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>Colorado</th>
      <td>7.9</td>
      <td>204</td>
      <td>78</td>
      <td>38.7</td>
    </tr>
    <tr>
      <th>Connecticut</th>
      <td>3.3</td>
      <td>110</td>
      <td>77</td>
      <td>11.1</td>
    </tr>
    <tr>
      <th>Delaware</th>
      <td>5.9</td>
      <td>238</td>
      <td>72</td>
      <td>15.8</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>15.4</td>
      <td>335</td>
      <td>80</td>
      <td>31.9</td>
    </tr>
    <tr>
      <th>Georgia</th>
      <td>17.4</td>
      <td>211</td>
      <td>60</td>
      <td>25.8</td>
    </tr>
    <tr>
      <th>Hawaii</th>
      <td>5.3</td>
      <td>46</td>
      <td>83</td>
      <td>20.2</td>
    </tr>
    <tr>
      <th>Idaho</th>
      <td>2.6</td>
      <td>120</td>
      <td>54</td>
      <td>14.2</td>
    </tr>
    <tr>
      <th>Illinois</th>
      <td>10.4</td>
      <td>249</td>
      <td>83</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>Indiana</th>
      <td>7.2</td>
      <td>113</td>
      <td>65</td>
      <td>21.0</td>
    </tr>
    <tr>
      <th>Iowa</th>
      <td>2.2</td>
      <td>56</td>
      <td>57</td>
      <td>11.3</td>
    </tr>
    <tr>
      <th>Kansas</th>
      <td>6.0</td>
      <td>115</td>
      <td>66</td>
      <td>18.0</td>
    </tr>
    <tr>
      <th>Kentucky</th>
      <td>9.7</td>
      <td>109</td>
      <td>52</td>
      <td>16.3</td>
    </tr>
    <tr>
      <th>Louisiana</th>
      <td>15.4</td>
      <td>249</td>
      <td>66</td>
      <td>22.2</td>
    </tr>
    <tr>
      <th>Maine</th>
      <td>2.1</td>
      <td>83</td>
      <td>51</td>
      <td>7.8</td>
    </tr>
    <tr>
      <th>Maryland</th>
      <td>11.3</td>
      <td>300</td>
      <td>67</td>
      <td>27.8</td>
    </tr>
    <tr>
      <th>Massachusetts</th>
      <td>4.4</td>
      <td>149</td>
      <td>85</td>
      <td>16.3</td>
    </tr>
    <tr>
      <th>Michigan</th>
      <td>12.1</td>
      <td>255</td>
      <td>74</td>
      <td>35.1</td>
    </tr>
    <tr>
      <th>Minnesota</th>
      <td>2.7</td>
      <td>72</td>
      <td>66</td>
      <td>14.9</td>
    </tr>
    <tr>
      <th>Mississippi</th>
      <td>16.1</td>
      <td>259</td>
      <td>44</td>
      <td>17.1</td>
    </tr>
    <tr>
      <th>Missouri</th>
      <td>9.0</td>
      <td>178</td>
      <td>70</td>
      <td>28.2</td>
    </tr>
    <tr>
      <th>Montana</th>
      <td>6.0</td>
      <td>109</td>
      <td>53</td>
      <td>16.4</td>
    </tr>
    <tr>
      <th>Nebraska</th>
      <td>4.3</td>
      <td>102</td>
      <td>62</td>
      <td>16.5</td>
    </tr>
    <tr>
      <th>Nevada</th>
      <td>12.2</td>
      <td>252</td>
      <td>81</td>
      <td>46.0</td>
    </tr>
    <tr>
      <th>New Hampshire</th>
      <td>2.1</td>
      <td>57</td>
      <td>56</td>
      <td>9.5</td>
    </tr>
    <tr>
      <th>New Jersey</th>
      <td>7.4</td>
      <td>159</td>
      <td>89</td>
      <td>18.8</td>
    </tr>
    <tr>
      <th>New Mexico</th>
      <td>11.4</td>
      <td>285</td>
      <td>70</td>
      <td>32.1</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>11.1</td>
      <td>254</td>
      <td>86</td>
      <td>26.1</td>
    </tr>
    <tr>
      <th>North Carolina</th>
      <td>13.0</td>
      <td>337</td>
      <td>45</td>
      <td>16.1</td>
    </tr>
    <tr>
      <th>North Dakota</th>
      <td>0.8</td>
      <td>45</td>
      <td>44</td>
      <td>7.3</td>
    </tr>
    <tr>
      <th>Ohio</th>
      <td>7.3</td>
      <td>120</td>
      <td>75</td>
      <td>21.4</td>
    </tr>
    <tr>
      <th>Oklahoma</th>
      <td>6.6</td>
      <td>151</td>
      <td>68</td>
      <td>20.0</td>
    </tr>
    <tr>
      <th>Oregon</th>
      <td>4.9</td>
      <td>159</td>
      <td>67</td>
      <td>29.3</td>
    </tr>
    <tr>
      <th>Pennsylvania</th>
      <td>6.3</td>
      <td>106</td>
      <td>72</td>
      <td>14.9</td>
    </tr>
    <tr>
      <th>Rhode Island</th>
      <td>3.4</td>
      <td>174</td>
      <td>87</td>
      <td>8.3</td>
    </tr>
    <tr>
      <th>South Carolina</th>
      <td>14.4</td>
      <td>279</td>
      <td>48</td>
      <td>22.5</td>
    </tr>
    <tr>
      <th>South Dakota</th>
      <td>3.8</td>
      <td>86</td>
      <td>45</td>
      <td>12.8</td>
    </tr>
    <tr>
      <th>Tennessee</th>
      <td>13.2</td>
      <td>188</td>
      <td>59</td>
      <td>26.9</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>12.7</td>
      <td>201</td>
      <td>80</td>
      <td>25.5</td>
    </tr>
    <tr>
      <th>Utah</th>
      <td>3.2</td>
      <td>120</td>
      <td>80</td>
      <td>22.9</td>
    </tr>
    <tr>
      <th>Vermont</th>
      <td>2.2</td>
      <td>48</td>
      <td>32</td>
      <td>11.2</td>
    </tr>
    <tr>
      <th>Virginia</th>
      <td>8.5</td>
      <td>156</td>
      <td>63</td>
      <td>20.7</td>
    </tr>
    <tr>
      <th>Washington</th>
      <td>4.0</td>
      <td>145</td>
      <td>73</td>
      <td>26.2</td>
    </tr>
    <tr>
      <th>West Virginia</th>
      <td>5.7</td>
      <td>81</td>
      <td>39</td>
      <td>9.3</td>
    </tr>
    <tr>
      <th>Wisconsin</th>
      <td>2.6</td>
      <td>53</td>
      <td>66</td>
      <td>10.8</td>
    </tr>
    <tr>
      <th>Wyoming</th>
      <td>6.8</td>
      <td>161</td>
      <td>60</td>
      <td>15.6</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The columns of the data set contain the four variables.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">USArrests</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;Murder&#39;, &#39;Assault&#39;, &#39;UrbanPop&#39;, &#39;Rape&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<p>We first briefly examine the data. We notice that the variables have vastly different means.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">USArrests</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Murder        7.788
Assault     170.760
UrbanPop     65.540
Rape         21.232
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Dataframes have several useful methods for computing
column-wise summaries. We can also examine the
variance of the four variables using the <code class="docutils literal notranslate"><span class="pre">var()</span></code>  method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">USArrests</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Murder        18.970465
Assault     6945.165714
UrbanPop     209.518776
Rape          87.729159
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Not surprisingly, the variables also have vastly different variances.
The <code class="docutils literal notranslate"><span class="pre">UrbanPop</span></code> variable measures the percentage of the population
in each state living in an urban area, which is not a comparable
number to the number of rapes in each state per 100,000 individuals.
PCA looks for derived variables that account for most of the variance in the data set.
If we do not scale the variables before performing PCA, then the principal components
would mostly be driven by the
<code class="docutils literal notranslate"><span class="pre">Assault</span></code> variable, since it has by far the largest
variance.  So if the variables are measured in different units or vary widely in scale, it is recommended to standardize the variables to have standard deviation one before performing PCA.
Typically we set the means to zero as well.</p>
<p>This scaling can be done via the <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code> transform imported above. We first <code class="docutils literal notranslate"><span class="pre">fit</span></code> the
scaler, which computes the necessary means and standard
deviations and then apply it to our data using the
<code class="docutils literal notranslate"><span class="pre">transform</span></code> method. As before, we combine these steps using the <code class="docutils literal notranslate"><span class="pre">fit_transform()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_std</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                        <span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">USArrests_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">USArrests</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Having scaled the data, we can then
perform principal components analysis using the <code class="docutils literal notranslate"><span class="pre">PCA()</span></code> transform
from the <code class="docutils literal notranslate"><span class="pre">sklearn.decomposition</span></code> package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>(By default, the <code class="docutils literal notranslate"><span class="pre">PCA()</span></code>  transform centers the variables to have
mean zero though it does not scale them.) The transform <code class="docutils literal notranslate"><span class="pre">pcaUS</span></code>
can be used to find the PCA
<code class="docutils literal notranslate"><span class="pre">scores</span></code> returned by <code class="docutils literal notranslate"><span class="pre">fit()</span></code>. Once the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method has been called, the <code class="docutils literal notranslate"><span class="pre">pcaUS</span></code> object also contains a number of useful quantities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">USArrests_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label sk-toggleable__label-arrow">PCA</label><div class="sk-toggleable__content"><pre>PCA()</pre></div></div></div></div></div></div></div>
</div>
<p>After fitting, the <code class="docutils literal notranslate"><span class="pre">mean_</span></code> attribute corresponds to the means
of the variables. In this case, since we centered and scaled the data with
<code class="docutils literal notranslate"><span class="pre">scaler()</span></code> the means will all be 0.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">mean_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-7.10542736e-17,  1.38777878e-16, -4.39648318e-16,  8.59312621e-16])
</pre></div>
</div>
</div>
</div>
<p>The scores can be computed using the <code class="docutils literal notranslate"><span class="pre">transform()</span></code> method
of <code class="docutils literal notranslate"><span class="pre">pcaUS</span></code> after it has been fit.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">pcaUS</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">USArrests_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will plot these scores a bit further down.
The <code class="docutils literal notranslate"><span class="pre">components_</span></code> attribute provides the principal component loadings:
each row of <code class="docutils literal notranslate"><span class="pre">pcaUS.components_</span></code> contains the corresponding
principal component loading vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.53589947,  0.58318363,  0.27819087,  0.54343209],
       [ 0.41818087,  0.1879856 , -0.87280619, -0.16731864],
       [-0.34123273, -0.26814843, -0.37801579,  0.81777791],
       [ 0.6492278 , -0.74340748,  0.13387773,  0.08902432]])
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">biplot</span></code>  is a common visualization method used with
PCA. It is not built in as a standard
part of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>, though there are python
packages that do produce such plots. Here we
make a simple biplot manually.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span> <span class="c1"># which components</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">scores</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">scores</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">],</span> <span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">],</span>
            <span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">],</span>
            <span class="n">USArrests</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/55b4e321aa276d5f6e4af9904f6ddd1c681fad9139d039eac68e22b9116e53e5.png" src="../../../_images/55b4e321aa276d5f6e4af9904f6ddd1c681fad9139d039eac68e22b9116e53e5.png" />
</div>
</div>
<p>Notice that this figure is a reflection of Figure 12.1 through the <span class="math notranslate nohighlight">\(y\)</span>-axis. Recall that the
principal components are only unique up to a sign change, so we can
reproduce that figure by flipping the
signs of the second set of scores and loadings.
We also increase the length of the arrows to emphasize the loadings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scale_arrow</span> <span class="o">=</span> <span class="n">s_</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">scores</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span> <span class="c1"># flip the y-axis</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">scores</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">scores</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">s_</span><span class="o">*</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">],</span> <span class="n">s_</span><span class="o">*</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">s_</span><span class="o">*</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">k</span><span class="p">],</span>
            <span class="n">s_</span><span class="o">*</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">k</span><span class="p">],</span>
            <span class="n">USArrests</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/bdd9056f25d16d7d30f8ceed14b63532606bde0a2c67396d88b2dfce011d1976.png" src="../../../_images/bdd9056f25d16d7d30f8ceed14b63532606bde0a2c67396d88b2dfce011d1976.png" />
</div>
</div>
<p>The standard deviations of the principal component scores are as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.5908673 , 1.00496987, 0.6031915 , 0.4206774 ])
</pre></div>
</div>
</div>
</div>
<p>The variance of each score can be extracted directly from the <code class="docutils literal notranslate"><span class="pre">pcaUS</span></code> object via
the <code class="docutils literal notranslate"><span class="pre">explained_variance_</span></code> attribute.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">explained_variance_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([2.53085875, 1.00996444, 0.36383998, 0.17696948])
</pre></div>
</div>
</div>
</div>
<p>The proportion of variance explained by each principal
component (PVE) is stored as <code class="docutils literal notranslate"><span class="pre">explained_variance_ratio_</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">explained_variance_ratio_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.62006039, 0.24744129, 0.0891408 , 0.04335752])
</pre></div>
</div>
</div>
</div>
<p>We see that the first principal component explains 62.0% of the
variance in the data, the next principal component explains 24.7%
of the variance, and so forth.
We can plot the PVE explained by each component, as well as the cumulative PVE. We first
plot the proportion of variance explained.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pcaUS</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ticks</span><span class="p">,</span>
        <span class="n">pcaUS</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Proportion of Variance Explained&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Notice the use of <code class="docutils literal notranslate"><span class="pre">%%capture</span></code>, which suppresses the displaying of the partially completed figure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ticks</span><span class="p">,</span>
        <span class="n">pcaUS</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(),</span>
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative Proportion of Variance Explained&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
<span class="n">fig</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/b581ed8946ca8b90d1df0f75eef05ff5fd88ddf42321a37171b325962784a274.png" src="../../../_images/b581ed8946ca8b90d1df0f75eef05ff5fd88ddf42321a37171b325962784a274.png" />
</div>
</div>
<p>The result is similar to that shown in Figure 12.3.  Note
that the method <code class="docutils literal notranslate"><span class="pre">cumsum()</span></code>   computes the cumulative sum of
the elements of a numeric vector. For instance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 1,  3, 11,  8])
</pre></div>
</div>
</div>
</div>
</section>
<section id="matrix-completion">
<h2>Matrix Completion<a class="headerlink" href="#matrix-completion" title="Permalink to this heading">#</a></h2>
<p>We now re-create the analysis carried out on the <code class="docutils literal notranslate"><span class="pre">USArrests</span></code> data in
Section 12.3.</p>
<p>We saw  in Section 12.2.2  that solving the optimization
problem (12.6)   on a centered data matrix <span class="math notranslate nohighlight">\(\bf X\)</span> is
equivalent to computing the first <span class="math notranslate nohighlight">\(M\)</span> principal
components of the data.  We use our scaled
and centered <code class="docutils literal notranslate"><span class="pre">USArrests</span></code> data as <span class="math notranslate nohighlight">\(\bf X\)</span> below. The <em>singular value decomposition</em>
(SVD)  is a general algorithm for solving
(12.6).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">USArrests_scaled</span>
<span class="n">U</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">V</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((50, 4), (4,), (4, 4))
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">np.linalg.svd()</span></code> function returns three components, <code class="docutils literal notranslate"><span class="pre">U</span></code>, <code class="docutils literal notranslate"><span class="pre">D</span></code> and <code class="docutils literal notranslate"><span class="pre">V</span></code>. The matrix <code class="docutils literal notranslate"><span class="pre">V</span></code> is equivalent to the
loading matrix from principal components (up to an unimportant sign flip). Using the <code class="docutils literal notranslate"><span class="pre">full_matrices=False</span></code> option ensures that
for a tall matrix the shape of <code class="docutils literal notranslate"><span class="pre">U</span></code> is the same as the shape of <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">V</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.53589947, -0.58318363, -0.27819087, -0.54343209],
       [-0.41818087, -0.1879856 ,  0.87280619,  0.16731864],
       [ 0.34123273,  0.26814843,  0.37801579, -0.81777791],
       [ 0.6492278 , -0.74340748,  0.13387773,  0.08902432]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pcaUS</span><span class="o">.</span><span class="n">components_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.53589947,  0.58318363,  0.27819087,  0.54343209],
       [-0.41818087, -0.1879856 ,  0.87280619,  0.16731864],
       [-0.34123273, -0.26814843, -0.37801579,  0.81777791],
       [ 0.6492278 , -0.74340748,  0.13387773,  0.08902432]])
</pre></div>
</div>
</div>
</div>
<p>The matrix <code class="docutils literal notranslate"><span class="pre">U</span></code> corresponds to a  <em>standardized</em> version of the PCA score matrix (each column standardized to have sum-of-squares one). If we multiply each column of <code class="docutils literal notranslate"><span class="pre">U</span></code> by the corresponding element  of <code class="docutils literal notranslate"><span class="pre">D</span></code>, we recover the PCA scores exactly (up to a meaningless sign flip).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">U</span> <span class="o">*</span> <span class="n">D</span><span class="p">[</span><span class="kc">None</span><span class="p">,:])[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.98556588, -1.13339238,  0.44426879,  0.15626714],
       [-1.95013775, -1.07321326, -2.04000333, -0.43858344],
       [-1.76316354,  0.74595678, -0.05478082, -0.83465292]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.98556588, -1.13339238, -0.44426879,  0.15626714],
       [ 1.95013775, -1.07321326,  2.04000333, -0.43858344],
       [ 1.76316354,  0.74595678,  0.05478082, -0.83465292]])
</pre></div>
</div>
</div>
</div>
<p>While it would be possible to carry out this lab using the <code class="docutils literal notranslate"><span class="pre">PCA()</span></code> estimator,
here we use the <code class="docutils literal notranslate"><span class="pre">np.linalg.svd()</span></code> function in order to illustrate its use.</p>
<p>We now omit 20 entries in the <span class="math notranslate nohighlight">\(50\times 4\)</span> data matrix at random. We do so
by first selecting 20 rows (states) at random, and then selecting one
of the four entries in each row at random. This ensures that every row has
at least three observed values.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_omit</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
<span class="n">r_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                         <span class="n">n_omit</span><span class="p">,</span>
                         <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">c_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                         <span class="n">n_omit</span><span class="p">,</span>
                         <span class="n">replace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Xna</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">Xna</span><span class="p">[</span><span class="n">r_idx</span><span class="p">,</span> <span class="n">c_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
</pre></div>
</div>
</div>
</div>
<p>Here the array <code class="docutils literal notranslate"><span class="pre">r_idx</span></code>
contains 20 integers from 0 to 49; this represents the states (rows of <code class="docutils literal notranslate"><span class="pre">X</span></code>) that are selected to contain missing values. And <code class="docutils literal notranslate"><span class="pre">c_idx</span></code> contains
20 integers from 0 to 3, representing the features (columns in <code class="docutils literal notranslate"><span class="pre">X</span></code>) that contain the missing values for each of the selected states.</p>
<p>We now write some code to implement Algorithm 12.1.
We first write a  function that takes in a matrix, and returns an approximation to the matrix using the <code class="docutils literal notranslate"><span class="pre">svd()</span></code> function.
This will be needed in Step 2 of Algorithm 12.1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">low_rank</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">U</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">L</span> <span class="o">=</span> <span class="n">U</span><span class="p">[:,:</span><span class="n">M</span><span class="p">]</span> <span class="o">*</span> <span class="n">D</span><span class="p">[</span><span class="kc">None</span><span class="p">,:</span><span class="n">M</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">L</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">[:</span><span class="n">M</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>To conduct Step 1 of the algorithm, we initialize <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> — this is <span class="math notranslate nohighlight">\(\tilde{\bf X}\)</span> in Algorithm 12.1 —  by replacing
the missing values with the column means of the non-missing entries. These are stored in
<code class="docutils literal notranslate"><span class="pre">Xbar</span></code> below after running <code class="docutils literal notranslate"><span class="pre">np.nanmean()</span></code> over the row axis.
We make a copy so that when we assign values to <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> below we do not also overwrite the
values in <code class="docutils literal notranslate"><span class="pre">Xna</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xhat</span> <span class="o">=</span> <span class="n">Xna</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">Xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Xhat</span><span class="p">[</span><span class="n">r_idx</span><span class="p">,</span> <span class="n">c_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xbar</span><span class="p">[</span><span class="n">c_idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Before we begin Step 2, we set ourselves up to measure the progress of our
iterations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">1e-7</span>
<span class="n">rel_err</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">ismiss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">Xna</span><span class="p">)</span>
<span class="n">mssold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xhat</span><span class="p">[</span><span class="o">~</span><span class="n">ismiss</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">mss0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Xna</span><span class="p">[</span><span class="o">~</span><span class="n">ismiss</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here  <code class="docutils literal notranslate"><span class="pre">ismiss</span></code> is a logical matrix with the same dimensions as <code class="docutils literal notranslate"><span class="pre">Xna</span></code>;
a given element is <code class="docutils literal notranslate"><span class="pre">True</span></code> if the corresponding matrix element is missing. The notation <code class="docutils literal notranslate"><span class="pre">~ismiss</span></code> negates this boolean vector. This is useful
because it allows us to access both the missing and non-missing entries. We store the mean of the squared non-missing elements in <code class="docutils literal notranslate"><span class="pre">mss0</span></code>.
We store the mean squared error  of the non-missing elements  of the old version of <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> in <code class="docutils literal notranslate"><span class="pre">mssold</span></code> (which currently
agrees with <code class="docutils literal notranslate"><span class="pre">mss0</span></code>). We plan to store the mean squared error of the non-missing elements of the current version of <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> in <code class="docutils literal notranslate"><span class="pre">mss</span></code>, and will then
iterate Step 2 of  Algorithm 12.1  until the <em>relative error</em>, defined as
<code class="docutils literal notranslate"><span class="pre">(mssold</span> <span class="pre">-</span> <span class="pre">mss)</span> <span class="pre">/</span> <span class="pre">mss0</span></code>, falls below <code class="docutils literal notranslate"><span class="pre">thresh</span> <span class="pre">=</span> <span class="pre">1e-7</span></code>.
{Algorithm 12.1 tells us to iterate Step 2 until (12.14) is no longer decreasing. Determining whether (12.14)  is decreasing requires us only to keep track of <code class="docutils literal notranslate"><span class="pre">mssold</span> <span class="pre">-</span> <span class="pre">mss</span></code>. However, in practice, we keep track of <code class="docutils literal notranslate"><span class="pre">(mssold</span> <span class="pre">-</span> <span class="pre">mss)</span> <span class="pre">/</span> <span class="pre">mss0</span></code> instead: this makes it so that the number of iterations required for Algorithm 12.1 to converge does not depend on whether we multiplied the raw data <span class="math notranslate nohighlight">\(\bf X\)</span> by a constant factor.}</p>
<p>In Step 2(a) of Algorithm 12.1, we  approximate <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> using <code class="docutils literal notranslate"><span class="pre">low_rank()</span></code>; we call this <code class="docutils literal notranslate"><span class="pre">Xapp</span></code>. In Step 2(b), we  use <code class="docutils literal notranslate"><span class="pre">Xapp</span></code>  to update the estimates for elements in <code class="docutils literal notranslate"><span class="pre">Xhat</span></code> that are missing in <code class="docutils literal notranslate"><span class="pre">Xna</span></code>. Finally, in Step 2(c), we compute the relative error. These three steps are contained in the following <code class="docutils literal notranslate"><span class="pre">while</span></code> loop:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="n">rel_err</span> <span class="o">&gt;</span> <span class="n">thresh</span><span class="p">:</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Step 2(a)</span>
    <span class="n">Xapp</span> <span class="o">=</span> <span class="n">low_rank</span><span class="p">(</span><span class="n">Xhat</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Step 2(b)</span>
    <span class="n">Xhat</span><span class="p">[</span><span class="n">ismiss</span><span class="p">]</span> <span class="o">=</span> <span class="n">Xapp</span><span class="p">[</span><span class="n">ismiss</span><span class="p">]</span>
    <span class="c1"># Step 2(c)</span>
    <span class="n">mss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(((</span><span class="n">Xna</span> <span class="o">-</span> <span class="n">Xapp</span><span class="p">)[</span><span class="o">~</span><span class="n">ismiss</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">rel_err</span> <span class="o">=</span> <span class="p">(</span><span class="n">mssold</span> <span class="o">-</span> <span class="n">mss</span><span class="p">)</span> <span class="o">/</span> <span class="n">mss0</span>
    <span class="n">mssold</span> <span class="o">=</span> <span class="n">mss</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Iteration: </span><span class="si">{0}</span><span class="s2">, MSS:</span><span class="si">{1:.3f}</span><span class="s2">, Rel.Err </span><span class="si">{2:.2e}</span><span class="s2">&quot;</span>
          <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">mss</span><span class="p">,</span> <span class="n">rel_err</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration: 1, MSS:0.395, Rel.Err 5.99e-01
Iteration: 2, MSS:0.382, Rel.Err 1.33e-02
Iteration: 3, MSS:0.381, Rel.Err 1.44e-03
Iteration: 4, MSS:0.381, Rel.Err 1.79e-04
Iteration: 5, MSS:0.381, Rel.Err 2.58e-05
Iteration: 6, MSS:0.381, Rel.Err 4.22e-06
Iteration: 7, MSS:0.381, Rel.Err 7.65e-07
Iteration: 8, MSS:0.381, Rel.Err 1.48e-07
Iteration: 9, MSS:0.381, Rel.Err 2.95e-08
</pre></div>
</div>
</div>
</div>
<p>We see that after eight iterations, the relative error has fallen below <code class="docutils literal notranslate"><span class="pre">thresh</span> <span class="pre">=</span> <span class="pre">1e-7</span></code>, and so the algorithm terminates. When this happens, the mean squared error of the non-missing elements equals 0.381.</p>
<p>Finally, we compute the correlation between the 20 imputed values
and the actual values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">Xapp</span><span class="p">[</span><span class="n">ismiss</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">ismiss</span><span class="p">])[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7113567434297362
</pre></div>
</div>
</div>
</div>
<p>In this lab, we implemented  Algorithm 12.1  ourselves for didactic purposes. However, a reader who wishes to apply matrix completion to their data might look to more specialized <code class="docutils literal notranslate"><span class="pre">Python</span></code>  implementations.</p>
</section>
<section id="clustering">
<h2>Clustering<a class="headerlink" href="#clustering" title="Permalink to this heading">#</a></h2>
<section id="k-means-clustering">
<h3><span class="math notranslate nohighlight">\(K\)</span>-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this heading">#</a></h3>
<p>The estimator <code class="docutils literal notranslate"><span class="pre">sklearn.cluster.KMeans()</span></code>  performs <span class="math notranslate nohighlight">\(K\)</span>-means clustering in
<code class="docutils literal notranslate"><span class="pre">Python</span></code>.  We begin with a simple simulated example in which there
truly are two clusters in the data: the first 25 observations have a
mean shift relative to the next 25 observations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span><span class="mi">2</span><span class="p">));</span>
<span class="n">X</span><span class="p">[:</span><span class="mi">25</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">3</span><span class="p">;</span>
<span class="n">X</span><span class="p">[:</span><span class="mi">25</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">4</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<p>We now perform <span class="math notranslate nohighlight">\(K\)</span>-means clustering with <span class="math notranslate nohighlight">\(K=2\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We specify <code class="docutils literal notranslate"><span class="pre">random_state</span></code> to make the results reproducible.  The cluster assignments of the 50 observations are contained in <code class="docutils literal notranslate"><span class="pre">kmeans.labels_</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,
       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
       1, 1, 1, 1, 1, 1], dtype=int32)
</pre></div>
</div>
</div>
</div>
<p>The <span class="math notranslate nohighlight">\(K\)</span>-means clustering perfectly separated the observations into two
clusters even though we did not supply any group information to
<code class="docutils literal notranslate"><span class="pre">KMeans()</span></code>. We can plot the data, with each observation
colored according to its cluster assignment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;K-Means Clustering Results with K=2&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/e6693b47dd7eac051e9a1b81d674022bf3e1f86906ddda8804c6c813f44f5fb2.png" src="../../../_images/e6693b47dd7eac051e9a1b81d674022bf3e1f86906ddda8804c6c813f44f5fb2.png" />
</div>
</div>
<p>Here the observations can be easily plotted because they are
two-dimensional. If there were more than two variables then we could
instead perform PCA and plot the first two principal component score
vectors to represent the clusters.</p>
<p>In this example,   we knew that there really
were two clusters because we generated the data. However, for real
data, we do not know the true number of clusters, nor whether they  exist in any precise way. We could
instead have performed <span class="math notranslate nohighlight">\(K\)</span>-means clustering on this example with
<span class="math notranslate nohighlight">\(K=3\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;K-Means Clustering Results with K=3&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/eac61cde223ecd23d76a75231a6bfff45eb1af92813726d5faabde83d767fdfd.png" src="../../../_images/eac61cde223ecd23d76a75231a6bfff45eb1af92813726d5faabde83d767fdfd.png" />
</div>
</div>
<p>When <span class="math notranslate nohighlight">\(K=3\)</span>, <span class="math notranslate nohighlight">\(K\)</span>-means clustering  splits up the two clusters.
We have used the <code class="docutils literal notranslate"><span class="pre">n_init</span></code> argument to run the <span class="math notranslate nohighlight">\(K\)</span>-means with 20
initial cluster assignments (the default is 10). If a
value of <code class="docutils literal notranslate"><span class="pre">n_init</span></code> greater than one is used, then <span class="math notranslate nohighlight">\(K\)</span>-means
clustering will be performed using multiple random assignments in
Step 1 of  Algorithm 12.2, and the <code class="docutils literal notranslate"><span class="pre">KMeans()</span></code>
function will report only the best results. Here we compare using
<code class="docutils literal notranslate"><span class="pre">n_init=1</span></code> to <code class="docutils literal notranslate"><span class="pre">n_init=20</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kmeans1</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">n_init</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">kmeans20</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                  <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                  <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">);</span>
<span class="n">kmeans1</span><span class="o">.</span><span class="n">inertia_</span><span class="p">,</span> <span class="n">kmeans20</span><span class="o">.</span><span class="n">inertia_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(76.85131986999251, 75.06261242745384)
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">kmeans.inertia_</span></code> is the total within-cluster sum
of squares, which we seek to minimize by performing <span class="math notranslate nohighlight">\(K\)</span>-means
clustering (12.17).</p>
<p>We <em>strongly</em> recommend always running <span class="math notranslate nohighlight">\(K\)</span>-means clustering with
a large value of <code class="docutils literal notranslate"><span class="pre">n_init</span></code>, such as 20 or 50, since otherwise an
undesirable local optimum may be obtained.</p>
<p>When performing <span class="math notranslate nohighlight">\(K\)</span>-means clustering, in addition to using multiple
initial cluster assignments, it is also important to set a random seed
using the <code class="docutils literal notranslate"><span class="pre">random_state</span></code> argument to <code class="docutils literal notranslate"><span class="pre">KMeans()</span></code>. This way, the initial
cluster assignments in Step 1 can be replicated, and the <span class="math notranslate nohighlight">\(K\)</span>-means
output will be fully reproducible.</p>
</section>
<section id="hierarchical-clustering">
<h3>Hierarchical Clustering<a class="headerlink" href="#hierarchical-clustering" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">AgglomerativeClustering()</span></code>  class from
the <code class="docutils literal notranslate"><span class="pre">sklearn.clustering</span></code> package implements hierarchical clustering.
As its
name is long, we use the short hand <code class="docutils literal notranslate"><span class="pre">HClust</span></code> for <em>hierarchical clustering</em>. Note that this will not change the return type
when using this method, so instances will still be of class <code class="docutils literal notranslate"><span class="pre">AgglomerativeClustering</span></code>.
In the following example we use the data from the previous lab to plot the hierarchical clustering
dendrogram using complete, single, and average linkage clustering
with Euclidean distance as the dissimilarity measure.  We begin by
clustering observations using complete linkage.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">HClust</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span>
<span class="n">hc_comp</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;complete&#39;</span><span class="p">)</span>
<span class="n">hc_comp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;complete&#x27;,
                        n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label sk-toggleable__label-arrow">AgglomerativeClustering</label><div class="sk-toggleable__content"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;complete&#x27;,
                        n_clusters=None)</pre></div></div></div></div></div></div></div>
</div>
<p>This computes the entire dendrogram.
We could just as easily perform hierarchical clustering with average or single linkage instead:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hc_avg</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">);</span>
<span class="n">hc_avg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">hc_sing</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">);</span>
<span class="n">hc_sing</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>To use a precomputed distance matrix, we provide an additional
argument <code class="docutils literal notranslate"><span class="pre">metric=&quot;precomputed&quot;</span></code>. In the code below, the first four lines computes the <span class="math notranslate nohighlight">\(50\times 50\)</span> pairwise-distance matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]));</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">x_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">multiply</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">D</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">x_</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">));</span>
<span class="n">hc_sing_pre</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                     <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span>
                     <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;single&#39;</span><span class="p">)</span>
<span class="n">hc_sing_pre</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;single&#x27;,
                        metric=&#x27;precomputed&#x27;, n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox" checked><label for="sk-estimator-id-3" class="sk-toggleable__label sk-toggleable__label-arrow">AgglomerativeClustering</label><div class="sk-toggleable__content"><pre>AgglomerativeClustering(distance_threshold=0, linkage=&#x27;single&#x27;,
                        metric=&#x27;precomputed&#x27;, n_clusters=None)</pre></div></div></div></div></div></div></div>
</div>
<p>We use
<code class="docutils literal notranslate"><span class="pre">dendrogram()</span></code> from <code class="docutils literal notranslate"><span class="pre">scipy.cluster.hierarchy</span></code> to plot the dendrogram. However,
<code class="docutils literal notranslate"><span class="pre">dendrogram()</span></code> expects a so-called <em>linkage-matrix representation</em>
of the clustering, which is not provided by <code class="docutils literal notranslate"><span class="pre">AgglomerativeClustering()</span></code>,
but can be computed. The function <code class="docutils literal notranslate"><span class="pre">compute_linkage()</span></code> in the
<code class="docutils literal notranslate"><span class="pre">ISLP.cluster</span></code> package is provided for this purpose.</p>
<p>We can now plot the dendrograms. The numbers at the bottom of the plot
identify each observation. The <code class="docutils literal notranslate"><span class="pre">dendrogram()</span></code> function has a default method to
color different branches of the tree that suggests a pre-defined cut of the tree at a particular depth.
We prefer to overwrite this default by setting this threshold to be infinite. Since we want this behavior for many dendrograms, we store these values in a dictionary <code class="docutils literal notranslate"><span class="pre">cargs</span></code> and pass this as keyword arguments using the notation <code class="docutils literal notranslate"><span class="pre">**cargs</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;color_threshold&#39;</span><span class="p">:</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
         <span class="s1">&#39;above_threshold_color&#39;</span><span class="p">:</span><span class="s1">&#39;black&#39;</span><span class="p">}</span>
<span class="n">linkage_comp</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc_comp</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_comp</span><span class="p">,</span>
           <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
           <span class="o">**</span><span class="n">cargs</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/31f6e5c6c07f77088d9c950a86781946d8ecedda294a4483421c59add4a037cb.png" src="../../../_images/31f6e5c6c07f77088d9c950a86781946d8ecedda294a4483421c59add4a037cb.png" />
</div>
</div>
<p>We may want to color branches of the tree above
and below a cut-threshold differently. This can be achieved
by changing the <code class="docutils literal notranslate"><span class="pre">color_threshold</span></code>. Let’s cut the tree at a height of 4,
coloring links that merge above 4 in black.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_comp</span><span class="p">,</span>
           <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
           <span class="n">color_threshold</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
           <span class="n">above_threshold_color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/8e0288f940aefc127e4341063dbad3c7878e40726b78a0d4ee51eecc0f8d24e3.png" src="../../../_images/8e0288f940aefc127e4341063dbad3c7878e40726b78a0d4ee51eecc0f8d24e3.png" />
</div>
</div>
<p>To determine the cluster labels for each observation associated with a
given cut of the dendrogram, we can use the <code class="docutils literal notranslate"><span class="pre">cut_tree()</span></code>
function from <code class="docutils literal notranslate"><span class="pre">scipy.cluster.hierarchy</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cut_tree</span><span class="p">(</span><span class="n">linkage_comp</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2,
        0, 2, 2, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3,
        3, 3, 3, 3, 3, 3]])
</pre></div>
</div>
</div>
</div>
<p>This can also be achieved by providing an argument <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>
to <code class="docutils literal notranslate"><span class="pre">HClust()</span></code>; however each cut would require recomputing
the clustering. Similarly, trees may be cut by distance threshold
with an argument of <code class="docutils literal notranslate"><span class="pre">distance_threshold</span></code> to <code class="docutils literal notranslate"><span class="pre">HClust()</span></code>
or <code class="docutils literal notranslate"><span class="pre">height</span></code> to <code class="docutils literal notranslate"><span class="pre">cut_tree()</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cut_tree</span><span class="p">(</span><span class="n">linkage_comp</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [1],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [0],
       [1],
       [0],
       [1],
       [1],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [1],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2],
       [2]])
</pre></div>
</div>
</div>
</div>
<p>To scale the variables before performing hierarchical clustering of
the observations, we use <code class="docutils literal notranslate"><span class="pre">StandardScaler()</span></code>  as in our PCA example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_scale</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">hc_comp_scale</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                       <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                       <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;complete&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_scale</span><span class="p">)</span>
<span class="n">linkage_comp_scale</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc_comp_scale</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_comp_scale</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="o">**</span><span class="n">cargs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Hierarchical Clustering with Scaled Features&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/8376480cb0af53e838afc9ae15668f838a8b069e45510ffbeced789c0dd26435.png" src="../../../_images/8376480cb0af53e838afc9ae15668f838a8b069e45510ffbeced789c0dd26435.png" />
</div>
</div>
<p>Correlation-based distances between observations can be used for
clustering. The correlation between two observations measures the
similarity of their feature values. {Suppose each observation has
<span class="math notranslate nohighlight">\(p\)</span> features, each a single numerical value. We measure the
similarity of two such observations by computing the
correlation of these <span class="math notranslate nohighlight">\(p\)</span> pairs of numbers.}
With <span class="math notranslate nohighlight">\(n\)</span> observations, the <span class="math notranslate nohighlight">\(n\times n\)</span> correlation matrix can then be used as a similarity (or affinity) matrix, i.e. so that one minus the correlation matrix is the dissimilarity matrix used for clustering.</p>
<p>Note that using correlation only makes sense for
data with at least three features since the absolute correlation
between any two observations with measurements on two features is
always one. Hence, we will cluster a three-dimensional data set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">corD</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">hc_cor</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;complete&#39;</span><span class="p">,</span>
                <span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">)</span>
<span class="n">hc_cor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corD</span><span class="p">)</span>
<span class="n">linkage_cor</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc_cor</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_cor</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="o">**</span><span class="n">cargs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Complete Linkage with Correlation-Based Dissimilarity&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/338efadb8ff6de39f53df8dd97fed87561e140e1352b15aafe01e15b2bb98b8b.png" src="../../../_images/338efadb8ff6de39f53df8dd97fed87561e140e1352b15aafe01e15b2bb98b8b.png" />
</div>
</div>
</section>
</section>
<section id="nci60-data-example">
<h2>NCI60 Data Example<a class="headerlink" href="#nci60-data-example" title="Permalink to this heading">#</a></h2>
<p>Unsupervised techniques are often used in the analysis of genomic
data. In particular, PCA and hierarchical clustering are popular
tools.  We illustrate these techniques on the <code class="docutils literal notranslate"><span class="pre">NCI60</span></code>  cancer cell line
microarray data, which consists of 6830 gene expression
measurements on 64 cancer cell lines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">NCI60</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="s1">&#39;NCI60&#39;</span><span class="p">)</span>
<span class="n">nci_labs</span> <span class="o">=</span> <span class="n">NCI60</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
<span class="n">nci_data</span> <span class="o">=</span> <span class="n">NCI60</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Each cell line is labeled with a cancer type. We do not make use of
the cancer types in performing PCA and clustering, as these are
unsupervised techniques. But after performing PCA and clustering, we
will check to see the extent to which these cancer types agree with
the results of these unsupervised techniques.</p>
<p>The data has 64 rows and 6830 columns.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nci_data</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(64, 6830)
</pre></div>
</div>
</div>
</div>
<p>We begin by examining the cancer types for the cell lines.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nci_labs</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>label      
NSCLC          9
RENAL          9
MELANOMA       8
BREAST         7
COLON          7
LEUKEMIA       6
OVARIAN        6
CNS            5
PROSTATE       2
K562A-repro    1
K562B-repro    1
MCF7A-repro    1
MCF7D-repro    1
UNKNOWN        1
Name: count, dtype: int64
</pre></div>
</div>
</div>
</div>
<section id="pca-on-the-nci60-data">
<h3>PCA on the NCI60 Data<a class="headerlink" href="#pca-on-the-nci60-data" title="Permalink to this heading">#</a></h3>
<p>We first perform PCA on the data after scaling the variables (genes)
to have standard deviation one, although here one could reasonably argue
that it is better not to scale the genes as they are measured in the same units.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">nci_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">nci_data</span><span class="p">)</span>
<span class="n">nci_pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">()</span>
<span class="n">nci_scores</span> <span class="o">=</span> <span class="n">nci_pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">nci_scaled</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We now plot the first few principal component score vectors, in order
to visualize the data. The observations (cell lines) corresponding to
a given cancer type will be plotted in the same color, so that we can
see to what extent the observations within a cancer type are similar
to each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer_types</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">nci_labs</span><span class="p">))</span>
<span class="n">nci_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">cancer_types</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">lab</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">lab</span> <span class="ow">in</span> <span class="n">nci_labs</span><span class="o">.</span><span class="n">values</span><span class="p">])</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">nci_scores</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
           <span class="n">nci_scores</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>
           <span class="n">c</span><span class="o">=</span><span class="n">nci_groups</span><span class="p">,</span>
           <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC2&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">nci_scores</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span>
           <span class="n">nci_scores</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span>
           <span class="n">c</span><span class="o">=</span><span class="n">nci_groups</span><span class="p">,</span>
           <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span>
           <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;PC1&#39;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PC3&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/a7f809fa838a7a818f365c6235daa8b6e530e12cb307a0915090f292918bc444.png" src="../../../_images/a7f809fa838a7a818f365c6235daa8b6e530e12cb307a0915090f292918bc444.png" />
</div>
</div>
<p>On the whole, cell lines corresponding to a single cancer type do tend to
have similar values on the first few principal component score
vectors. This indicates that cell lines from the same cancer type tend
to have pretty similar gene expression levels.</p>
<p>We can also plot the percent variance
explained by the principal components as well as the cumulative percent variance explained.
This is similar to the plots we made earlier for the <code class="docutils literal notranslate"><span class="pre">USArrests</span></code> data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">nci_pca</span><span class="o">.</span><span class="n">n_components_</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ticks</span><span class="p">,</span>
        <span class="n">nci_pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">,</span>
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;PVE&#39;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ticks</span><span class="p">,</span>
        <span class="n">nci_pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(),</span>
        <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">);</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Principal Component&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cumulative PVE&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/bdf640399ea6912eeb6f104fa971462649adb9bcf9c920f36e49ffa5b50f7362.png" src="../../../_images/bdf640399ea6912eeb6f104fa971462649adb9bcf9c920f36e49ffa5b50f7362.png" />
</div>
</div>
<p>We see that together, the first seven principal components explain
around 40% of the variance in the data. This is not a huge amount
of the variance. However, looking at the scree plot, we see that while
each of the first seven principal components explain a substantial
amount of variance, there is a marked decrease in the variance
explained by further principal components. That is, there is an
<em>elbow</em>  in the plot after approximately the seventh
principal component.  This suggests that there may be little benefit
to examining more than seven or so principal components (though even
examining seven principal components may be difficult).</p>
</section>
<section id="clustering-the-observations-of-the-nci60-data">
<h3>Clustering the Observations of the NCI60 Data<a class="headerlink" href="#clustering-the-observations-of-the-nci60-data" title="Permalink to this heading">#</a></h3>
<p>We now perform hierarchical clustering of the cell lines in the <code class="docutils literal notranslate"><span class="pre">NCI60</span></code> data using
complete, single, and   average linkage. Once again, the goal is to find out whether or not the observations cluster into distinct types of cancer. Euclidean
distance is used as the dissimilarity measure. We first write a short
function to  produce
the three dendrograms.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_nci</span><span class="p">(</span><span class="n">linkage</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">cut</span><span class="o">=-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">):</span>
    <span class="n">cargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;above_threshold_color&#39;</span><span class="p">:</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
             <span class="s1">&#39;color_threshold&#39;</span><span class="p">:</span><span class="n">cut</span><span class="p">}</span>
    <span class="n">hc</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">linkage</span><span class="o">=</span><span class="n">linkage</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nci_scaled</span><span class="p">)</span>
    <span class="n">linkage_</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc</span><span class="p">)</span>
    <span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_</span><span class="p">,</span>
               <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
               <span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nci_labs</span><span class="p">),</span>
               <span class="n">leaf_font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="o">**</span><span class="n">cargs</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> Linkage&#39;</span> <span class="o">%</span> <span class="n">linkage</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">hc</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s  plot our results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">30</span><span class="p">))</span>      
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span> <span class="n">hc_comp</span> <span class="o">=</span> <span class="n">plot_nci</span><span class="p">(</span><span class="s1">&#39;Complete&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span> <span class="n">hc_avg</span> <span class="o">=</span> <span class="n">plot_nci</span><span class="p">(</span><span class="s1">&#39;Average&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span> <span class="n">hc_sing</span> <span class="o">=</span> <span class="n">plot_nci</span><span class="p">(</span><span class="s1">&#39;Single&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/cd46bd5d76a612f2650d83a0f009a7c692531fdc4254f4af85b4c6838d6d1958.png" src="../../../_images/cd46bd5d76a612f2650d83a0f009a7c692531fdc4254f4af85b4c6838d6d1958.png" />
</div>
</div>
<p>We see that the
choice of linkage certainly does affect the results
obtained. Typically, single linkage will tend to yield <em>trailing</em>
clusters: very large clusters onto which individual observations
attach one-by-one. On the other hand, complete and average linkage
tend to yield more balanced, attractive clusters. For this reason,
complete and average linkage are generally preferred to single
linkage.  Clearly cell lines within a single cancer type do tend to
cluster together, although the clustering is not perfect. We will use
complete linkage hierarchical clustering for the analysis that
follows.</p>
<p>We can cut the dendrogram at the height that will yield a particular
number of clusters, say four:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linkage_comp</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc_comp</span><span class="p">)</span>
<span class="n">comp_cut</span> <span class="o">=</span> <span class="n">cut_tree</span><span class="p">(</span><span class="n">linkage_comp</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">nci_labs</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">comp_cut</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Complete&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Complete</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
    <tr>
      <th>label</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>BREAST</th>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>CNS</th>
      <td>3</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>COLON</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>K562A-repro</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>K562B-repro</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>LEUKEMIA</th>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
    </tr>
    <tr>
      <th>MCF7A-repro</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>MCF7D-repro</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>MELANOMA</th>
      <td>8</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>NSCLC</th>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>OVARIAN</th>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>PROSTATE</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>RENAL</th>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>UNKNOWN</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>There are some clear patterns. All the leukemia cell lines fall in
one cluster, while the breast cancer cell lines are spread out over
three different clusters.</p>
<p>We can plot a cut on the dendrogram that produces these four clusters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plot_nci</span><span class="p">(</span><span class="s1">&#39;Complete&#39;</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">cut</span><span class="o">=</span><span class="mi">140</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">140</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/b27f62d090db96c9088f958ed8e4374937381dad7ce6680aa42cbe7fb15e5889.png" src="../../../_images/b27f62d090db96c9088f958ed8e4374937381dad7ce6680aa42cbe7fb15e5889.png" />
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">axhline()</span></code>  function draws a horizontal line  line on top of any
existing set of axes. The argument <code class="docutils literal notranslate"><span class="pre">140</span></code> plots a horizontal
line at height 140 on the dendrogram; this is a height that
results in four distinct clusters. It is easy to verify that the
resulting clusters are the same as the ones we obtained in
<code class="docutils literal notranslate"><span class="pre">comp_cut</span></code>.</p>
<p>We claimed earlier in Section 12.4.2 that
<span class="math notranslate nohighlight">\(K\)</span>-means clustering and hierarchical clustering with the dendrogram
cut to obtain the same number of clusters can yield very different
results.  How do these <code class="docutils literal notranslate"><span class="pre">NCI60</span></code> hierarchical clustering results compare
to what we get if we perform <span class="math notranslate nohighlight">\(K\)</span>-means clustering with <span class="math notranslate nohighlight">\(K=4\)</span>?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nci_kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                    <span class="n">n_init</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nci_scaled</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">comp_cut</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;HClust&#39;</span><span class="p">),</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">nci_kmeans</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;K-means&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>K-means</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
    <tr>
      <th>HClust</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>20</td>
      <td>10</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>9</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We see that the four clusters obtained using hierarchical clustering
and <span class="math notranslate nohighlight">\(K\)</span>-means clustering are somewhat different. First we note
that the labels in the two clusterings are arbitrary. That is, swapping
the identifier of the cluster does not
change the clustering. We see here Cluster 3 in
<span class="math notranslate nohighlight">\(K\)</span>-means clustering is identical to cluster 2 in hierarchical
clustering. However, the other clusters differ: for instance,
cluster 0 in <span class="math notranslate nohighlight">\(K\)</span>-means clustering contains a portion of the
observations assigned to cluster 0 by hierarchical clustering, as well
as all of the observations assigned to cluster 1 by hierarchical
clustering.</p>
<p>Rather than performing hierarchical clustering on the entire data
matrix, we can also perform hierarchical clustering on the first few
principal component score vectors, regarding these first few components
as a less noisy version of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hc_pca</span> <span class="o">=</span> <span class="n">HClust</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">distance_threshold</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                <span class="n">linkage</span><span class="o">=</span><span class="s1">&#39;complete&#39;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">nci_scores</span><span class="p">[:,:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">linkage_pca</span> <span class="o">=</span> <span class="n">compute_linkage</span><span class="p">(</span><span class="n">hc_pca</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">dendrogram</span><span class="p">(</span><span class="n">linkage_pca</span><span class="p">,</span>
           <span class="n">labels</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">nci_labs</span><span class="p">),</span>
           <span class="n">leaf_font_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
           <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
           <span class="o">**</span><span class="n">cargs</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Hier. Clust. on First Five Score Vectors&quot;</span><span class="p">)</span>
<span class="n">pca_labels</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cut_tree</span><span class="p">(</span><span class="n">linkage_pca</span><span class="p">,</span>
                                <span class="n">n_clusters</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                       <span class="n">name</span><span class="o">=</span><span class="s1">&#39;Complete-PCA&#39;</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">nci_labs</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">],</span> <span class="n">pca_labels</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>Complete-PCA</th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
    <tr>
      <th>label</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>BREAST</th>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>CNS</th>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>COLON</th>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>K562A-repro</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>K562B-repro</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>LEUKEMIA</th>
      <td>2</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
    </tr>
    <tr>
      <th>MCF7A-repro</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>MCF7D-repro</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>MELANOMA</th>
      <td>1</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>NSCLC</th>
      <td>8</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>OVARIAN</th>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>PROSTATE</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>RENAL</th>
      <td>7</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>UNKNOWN</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div><img alt="../../../_images/75ee4ac7af483bdbee161719ea03a2b82ae45c1f7fff63a75fbbd42b6316d59b.png" src="../../../_images/75ee4ac7af483bdbee161719ea03a2b82ae45c1f7fff63a75fbbd42b6316d59b.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/labs/notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Ch11-surv-lab.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chapter 11</p>
      </div>
    </a>
    <a class="right-next"
       href="Ch13-multiple-lab.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Chapter 13</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Chapter 12</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#lab-unsupervised-learning">Lab: Unsupervised Learning</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#principal-components-analysis">Principal Components Analysis</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-completion">Matrix Completion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering">Clustering</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#k-means-clustering"><span class="math notranslate nohighlight">\(K\)</span>-Means Clustering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hierarchical-clustering">Hierarchical Clustering</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#nci60-data-example">NCI60 Data Example</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pca-on-the-nci60-data">PCA on the NCI60 Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#clustering-the-observations-of-the-nci60-data">Clustering the Observations of the NCI60 Data</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Trevor Hastie et al.
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>